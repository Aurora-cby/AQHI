{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from GetPath import GetPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "input_path='D:/Output/chenbingying/A1/'\n",
    "output_path='D:/Output/chenbingying/Check/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_A1(input_path,output_path):\n",
    "    t_start=time()\n",
    "    spark = SparkSession.builder.appName('A1_Check').config('spark.dynamicAllocation.enabled','true').config('spark.debug.maxToStringFields', '100').config('spark.sql.execution.arrow.enable','true').config('spark.executor.memory','48g').config('spark.driver.memory', '48g').config('spark.core.connection.ack.wait.timeout','36000s').config('spark.executor.heartbeatInterval','36000s').config('spark.network.timeout', '50000s').config('spark.rpc.lookupTimeout', '5000s').config('spark.shuffle.io.connectionTimeout', '50000s').getOrCreate()\n",
    "    start=time()\n",
    "    namelist=[]\n",
    "    resultlist=[]\n",
    "    for file in GetPath(input_path,'csv'):\n",
    "        name=file.split('/')[-1]\n",
    "        print(\"正在处理：\",name)\n",
    "        spark.read.option('inferSchema','true').option('header','true').csv(file).createOrReplaceTempView('A1_Raw')\n",
    "        print('读入数据耗时：%.2f秒'%(time()-start))\n",
    "        start=time()\n",
    "        df=spark.sql('''select \n",
    "            count(*) as TOTAL\n",
    "            ,count(MEDICAL_INSTITUTION_CODE) as MEDICAL_INSTITUTION_CODE\n",
    "            ,count(FILE_NUMBER) as FILE_NUMBER\n",
    "            ,count(ID_NUMBER) as ID_NUMBER\n",
    "            ,count(BIRTH_DATE) as BIRTH_DATE\n",
    "            ,count(GENDER) as GENDER\n",
    "            ,count(ADDRESS_OF_EMPLOYER) as ADDRESS_OF_EMPLOYER\n",
    "            ,count(RESIDENCE_ADDRESS) as RESIDENCE_ADDRESS\n",
    "            ,count(REGISTERED_ADDRESS) as REGISTERED_ADDRESS\n",
    "            ,count(AREA) as AREA\n",
    "            ,sum(case when ADDRESS_OF_EMPLOYER is not null or RESIDENCE_ADDRESS is not null or REGISTERED_ADDRESS is not null or AREA is not null then 1 else 0 end)\n",
    "            ,sum(case when MEDICAL_INSTITUTION_CODE is not null and FILE_NUMBER is not null then 1 else 0 end) as MF\n",
    "            ,sum(case when CARD_TYPE is not null and CARD_NUMBER is not null then 1 else 0 end) as CC\n",
    "            ,count(id_birth_date) as id_birth_date\n",
    "            ,count(id_gender) as id_gender\n",
    "            from A1_Raw\n",
    "        ''').toPandas()\n",
    "        for i in df.columns:\n",
    "            if(i!='TOTAL'):\n",
    "                df.insert(df.columns.get_loc(i)+1,i+'_RATE',df[i]/df['TOTAL']*100)\n",
    "        resultlist.append(df)\n",
    "        namelist.append(name)\n",
    "        print('处理数据耗时：%.2f秒'%(time()-start))\n",
    "    result_df=pd.concat(resultlist)\n",
    "    result_df.insert(0,'文件名',namelist)\n",
    "    result_df.columns=['文件名','数据总量','MEDICAL_INSTITUTION_CODE非空数据量','MEDICAL_INSTITUTION_CODE完整率','FILE_NUMBER非空数据量','FILE_NUMBER完整率','ID_NUMBER非空数据量','ID_NUMBER完整率','BIRTH_DATE非空数据量','BIRTH_DATE完整率','GENDER非空数据量','GENDER完整率','ADDRESS_OF_EMPLOYER非空数据量','ADDRESS_OF_EMPLOYER完整率','RESIDENCE_ADDRESS非空数据量','RESIDENCE_ADDRESS完整率','REGISTERED_ADDRESS非空数据量','REGISTERED_ADDRESS完整率','AREA非空数据量','AREA完整率','任一ADDRESS非空数据量','任一ADDRESS非空占比','MEDICAL_INSTITUTION_CODE,FILE_NUMBER字段组合非空个数==2数据量','MEDICAL_INSTITUTION_CODE,FILE_NUMBER字段组合非空个数==2占比','CARD_TYPE,CARD_NUMBER字段组合非空个数==2数据量','CARD_TYPE,CARD_NUMBER字段组合非空个数==2占比','ID_BIRTH_DATE非空数据量','ID_BIRTH_DATE完整率','ID_GENDER非空数据量','ID_GENDER完整率']\n",
    "    result_df.to_csv(output_path+'A1统计.csv',index=None)\n",
    "    spark.catalog.dropTempView(\"A1_Raw\")\n",
    "    print(f'已输出至：{output_path}A1统计.csv')\n",
    "    print('总耗时：%.2f秒'%(time()-t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理： tb_patient_information.csv\n",
      "读入数据耗时：53.59秒\n",
      "处理数据耗时：72.21秒\n",
      "正在处理： tb_patient_information_201807.csv\n",
      "读入数据耗时：204.64秒\n",
      "处理数据耗时：78.63秒\n",
      "已输出至：D:/Output/zhuhao/Check/A1统计.csv\n",
      "总耗时：340.58秒\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    Check_A1(input_path,output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
