{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from time import time\n",
    "from functools import reduce\n",
    "from GetPath import *\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "input_path='D:/Output/chenbingying/A1/'\n",
    "output_path='D:/Output/chenbingying/A2.csv'\n",
    "place_path='D:/Code/chenbingying/Data/Place.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 区匹配\n",
    "def Match_County(x,y):\n",
    "    if(y is not None):\n",
    "        if(y.find('广州市')!=-1):\n",
    "            y=y.split(\"广州市\")[1]\n",
    "            for i in [['芳村区','荔湾区'],['花县','花都区'],['东山区','越秀区'],['萝岗区','黄埔区']]: \n",
    "                y=y.replace(i[0],i[1])\n",
    "            return y\n",
    "    if(x is not None):\n",
    "        for i in [['芳村区','荔湾区'],['花县','花都区'],['东山区','越秀区'],['萝岗区','黄埔区']]:\n",
    "            x=x.replace(i[0],i[1])   \n",
    "        for i in ['荔湾','越秀','海珠','天河','白云','黄埔','番禺','花都','南沙','从化','增城']:\n",
    "            if i in str(x):\n",
    "                return i+'区'\n",
    "        x1=['沙面','岭南','华林','多宝','昌华','逢源','龙津','金花','彩虹','南源','西村','站前','桥中','白鹤洞','冲口','花地','石围塘','茶滘','东漖','海龙','东沙','中南','洪桥','北京','六榕','流花','光塔','人民','东山','农林','梅花村','黄花岗','华乐','建设','大塘','珠光','大东','白云','登峰','矿泉','赤岗','新港','昌岗','江南中','滨江','素社','海幢','南华西','龙凤','沙园','南石头','凤阳','瑞宝','江海','琶洲','南洲','华洲','官洲','五山','员村','车陂','沙河','石牌','沙东','天河南','林和','兴华','棠下','天园','猎德','冼村','元岗','黄村','长兴','龙洞','凤凰','前进','珠吉','新塘','三元里','松洲','景泰','同德','黄石','棠景','新市','同和','京溪','永平','嘉禾','均禾','石井','金沙','云城','鹤龙','白云湖','石门','大源','龙归','人和','太和','钟落潭','江高','黄埔','红山','鱼珠','大沙','文冲','穗东','南岗','长洲','夏港','萝岗','云埔','联和','永和','长岭','九佛','龙湖','新龙','市桥','沙头','东环','桥南','小谷围','大石','洛浦','石壁','钟村','大龙','南村','新造','化龙','石楼','沙湾','石基','新华','花城','秀全','新雅','梯面','花山','花东','炭步','赤坭','狮岭','南沙','珠江','龙穴','万顷沙','横沥','黄阁','东涌','大岗','榄核','街口','江埔','城郊','温泉','良口','吕田','太平','鳌头','黄龙带水库','大岭山林场','荔城','增江','朱村','永宁','荔湖','宁西','新塘','石滩','中新','正果','派潭','小楼','仙村','荔联','雅瑶','东区','九龙','流溪河林场','黄龙带水库管理处']\n",
    "        x2=['荔湾','荔湾','荔湾','荔湾','荔湾','荔湾','荔湾','荔湾','荔湾','荔湾','荔湾','荔湾','荔湾','荔湾','荔湾','荔湾','荔湾','荔湾','荔湾','荔湾','荔湾','荔湾','越秀','越秀','越秀','越秀','越秀','越秀','越秀','越秀','越秀','越秀','越秀','越秀','越秀','越秀','越秀','越秀','越秀','越秀','海珠','海珠','海珠','海珠','海珠','海珠','海珠','海珠','海珠','海珠','海珠','海珠','海珠','海珠','海珠','海珠','海珠','海珠','天河','天河','天河','天河','天河','天河','天河','天河','天河','天河','天河','天河','天河','天河','天河','天河','天河','天河','天河','天河','天河','白云','白云','白云','白云','白云','白云','白云','白云','白云','白云','白云','白云','白云','白云','白云','白云','白云','白云','白云','白云','白云','白云','白云','白云','黄埔','黄埔','黄埔','黄埔','黄埔','黄埔','黄埔','黄埔','黄埔','黄埔','黄埔','黄埔','黄埔','黄埔','黄埔','黄埔','黄埔','番禺','番禺','番禺','番禺','番禺','番禺','番禺','番禺','番禺','番禺','番禺','番禺','番禺','番禺','番禺','番禺','花都','花都','花都','花都','花都','花都','花都','花都','花都','花都','南沙','南沙','南沙','南沙','南沙','南沙','南沙','南沙','南沙','从化','从化','从化','从化','从化','从化','从化','从化','从化','从化','增城','增城','增城','增城','增城','增城','增城','增城','增城','增城','增城','增城','增城','黄埔','花都','黄埔','黄埔','从化','从化']\n",
    "        for i in range(len(x1)):\n",
    "            if(x1[i] in x):\n",
    "                return x2[i]+'区'\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 是否广州匹配\n",
    "def Is_GuangZhou(x):\n",
    "    if(x is not None):\n",
    "        for i in address:\n",
    "            if i in x:\n",
    "                return '广州市'\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_A2(input_path,output_path,place_path):\n",
    "    t_start=time()\n",
    "    spark= SparkSession.builder.appName('A2_Create').config('spark.dynamicAllocation.enabled','true').config('spark.debug.maxToStringFields', '100').config('spark.sql.execution.arrow.enable','true').config('spark.executor.memory','48g').config('spark.driver.memory', '48g').config('spark.core.connection.ack.wait.timeout','36000s').config('spark.executor.heartbeatInterval','36000s').config('spark.network.timeout', '50000s').config('spark.rpc.lookupTimeout', '5000s').config('spark.shuffle.io.connectionTimeout', '50000s').getOrCreate()\n",
    "    # 读取字典\n",
    "    address_df=pd.read_csv(place_path,header=0,encoding='GBK')\n",
    "    global address\n",
    "    address=[]\n",
    "    for i in address_df.columns:\n",
    "        address+=address_df[i].dropna().to_list()\n",
    "    # 读入文件\n",
    "    files=[]\n",
    "    filelist=GetPath(input_path,'tb_patient')\n",
    "    for file in filelist:\n",
    "        start=time()\n",
    "        print('开始处理：',file.split('/')[-1])\n",
    "        files.append(spark.read.option('inferSchema','true').option('header','true').csv(file))\n",
    "        print('读入数据耗时：%.2f秒'%(time()-start))\n",
    "    # 合并数据\n",
    "    start=time()\n",
    "    reduce(lambda x,y:x.unionByName(y), files).createOrReplaceTempView('A2_Raw')\n",
    "    # 注册函数\n",
    "    spark.udf.register('Match_County',Match_County,StringType())\n",
    "    spark.udf.register('Is_GuangZhou',Is_GuangZhou,StringType())\n",
    "    # 匹配数据\n",
    "    spark.sql('''\n",
    "    select MEDICAL_INSTITUTION_CODE\n",
    "    ,FILE_NUMBER\n",
    "    ,ID_NUMBER\n",
    "    ,CARD_NUMBER\n",
    "    ,CARD_TYPE\n",
    "    ,case when id_birth_date is not null then to_date(id_birth_date) else to_date(BIRTH_DATE) end as BIRTH_DATE\n",
    "    ,case when id_gender is not null then id_gender else GENDER end as GENDER\n",
    "    ,ADDRESS_OF_EMPLOYER\n",
    "    ,concat_ws('',CITY_OF_RESIDENCE,COUNTY_OF_RESIDENCE,RESIDENCE_ADDRESS) as RESIDENCE_ADDRESS\n",
    "    ,concat_ws('',CITY_OF_REG_RESIDENCE,COUNTY_OF_REG_RESIDENCE,REGISTERED_ADDRESS) as REGISTERED_ADDRESS\n",
    "    ,AREA\n",
    "    ,Is_GuangZhou(concat_ws('',ADDRESS_OF_EMPLOYER,CITY_OF_RESIDENCE,COUNTY_OF_RESIDENCE,RESIDENCE_ADDRESS,CITY_OF_REG_RESIDENCE,COUNTY_OF_REG_RESIDENCE,REGISTERED_ADDRESS,AREA)) as CITY\n",
    "    ,Match_County(concat_ws('',ADDRESS_OF_EMPLOYER,CITY_OF_RESIDENCE,COUNTY_OF_RESIDENCE,RESIDENCE_ADDRESS,CITY_OF_REG_RESIDENCE,COUNTY_OF_REG_RESIDENCE,REGISTERED_ADDRESS),AREA) as DISTRICT\n",
    "    from A2_Raw\n",
    "    ''').coalesce(1).write.csv(output_path+'A2',mode='overwrite',header=True)\n",
    "    # 释放资源\n",
    "    spark.catalog.dropTempView('A2_Raw')\n",
    "    shutil.move(GetPath(output_path+'A2/','csv'),output_path)\n",
    "    shutil.rmtree(output_path+'A2')\n",
    "    print('匹配完成，耗时：%.2f秒'%(time()-start))\n",
    "    print(f'已输出至：{output_path}')\n",
    "    print('总耗时：%.2f秒'%(time()-t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理： tb_patient_information.csv\n",
      "读入数据耗时：41.40秒\n",
      "开始处理： tb_patient_information_201807.csv\n",
      "读入数据耗时：79.57秒\n",
      "匹配完成，耗时：12252.95秒\n",
      "已输出至：D:/Output/zhuhao/A2.csv\n",
      "总耗时：12373.99秒\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    Create_A2(input_path,output_path,place_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
