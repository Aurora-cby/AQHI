{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "input_path='D:/Output/chenbingying/A2.csv'\n",
    "output_path='D:/Output/chenbingying/Check/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_A2(input_path,output_path):\n",
    "    t_start=time()\n",
    "    spark = SparkSession.builder.appName('A2_Check').config('spark.dynamicAllocation.enabled','true').config('spark.debug.maxToStringFields', '100').config('spark.sql.execution.arrow.enable','true').config('spark.executor.memory','48g').config('spark.driver.memory', '48g').config('spark.core.connection.ack.wait.timeout','36000s').config('spark.executor.heartbeatInterval','36000s').config('spark.network.timeout', '50000s').config('spark.rpc.lookupTimeout', '5000s').config('spark.shuffle.io.connectionTimeout', '50000s').getOrCreate()\n",
    "    print(\"正在处理：\",input_path)\n",
    "    start=time()\n",
    "    spark.read.option('inferSchema','true').option('header','true').csv(input_path).createOrReplaceTempView('A2_Raw')\n",
    "    print('读入数据耗时：%.2f秒'%(time()-start))\n",
    "    start=time()\n",
    "    df=spark.sql('''select \n",
    "        count(*) as TOTAL\n",
    "        ,count(ID_NUMBER) as ID_NUMBER\n",
    "        ,count(BIRTH_DATE) as BIRTH_DATE\n",
    "        ,count(GENDER) as GENDER\n",
    "        ,count(CITY) as CITY\n",
    "        ,count(DISTRICT) as DISTRICT\n",
    "        ,sum(case when MEDICAL_INSTITUTION_CODE is not null and FILE_NUMBER is not null then 1 else 0 end) as MF\n",
    "        ,sum(case when CARD_TYPE is not null and CARD_NUMBER is not null then 1 else 0 end) as CC\n",
    "        from A2_Raw\n",
    "    ''').toPandas()\n",
    "    for i in df.columns:\n",
    "        if(i!='TOTAL'):\n",
    "            df.insert(df.columns.get_loc(i)+1,i+'_RATE',df[i]/df['TOTAL']*100)\n",
    "    print('处理数据耗时：%.2f秒'%(time()-start))\n",
    "    df.columns=['数据总量','ID_NUMBER非空数据量','ID_NUMBER完整率','BIRTH_DATE非空数据量','BIRTH_DATE完整率','GENDER非空数据量','GENDER完整率','CITY非空数据量','CITY完整率','DISTRICT非空数据量','DISTRICT完整率','MEDICAL_INSTITUTION_CODE,FILE_NUMBER字段组合非空个数==2数据量','MEDICAL_INSTITUTION_CODE,FILE_NUMBER字段组合非空个数==2占比','CARD_TYPE,CARD_NUMBER字段组合非空个数==2数据量','CARD_TYPE,CARD_NUMBER字段组合非空个数==2占比']\n",
    "    df.to_csv(output_path+'A2统计.csv',index=None)\n",
    "    spark.catalog.dropTempView(\"A2_Raw\")\n",
    "    print(f'已输出至：{output_path}A2统计.csv')\n",
    "    print('总耗时：%.2f秒'%(time()-t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理  D:/Output/zhuhao/A2.csv\n",
      "读入数据耗时：37.88秒\n",
      "处理数据耗时：44.76秒\n",
      "已输出至：D:/Output/zhuhao/Check/A2统计.csv\n",
      "总耗时：82.65秒\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    Check_A2(input_path,output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
