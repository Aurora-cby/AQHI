{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e88e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "import findspark\n",
    "from pyspark.sql.types import *\n",
    "findspark.init()\n",
    "import statistics\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "from time import time\n",
    "import datatable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "spark = SparkSession.builder.master(\"local[*]\").config('spark.dynamicAllocation.enabled','true').config(\"spark.debug.maxToStringFields\", \"100\").config(\"spark.sql.execution.arrow.enable\",\"true\").config(\"spark.executor.memory\",\"20g\").config(\"spark.driver.memory\", \"20g\").config(\"spark.core.connection.ack.wait.timeout\",\"36000s\").config(\"spark.executor.heartbeatInterval\",\"36000s\").config(\"spark.network.timeout\", \"50000s\").config(\"spark.rpc.lookupTimeout\", \"5000s\").config(\"spark.shuffle.io.connectionTimeout\", \"50000s\").appName(\"data\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75676676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tb_cis_op_visiting_record_201401_201806.csv\n",
      "读入数据耗时：0.00秒\n",
      "处理数据耗时：94.99秒\n",
      "tb_cis_op_visiting_record_201807_201912.csv\n",
      "读入数据耗时：0.00秒\n",
      "处理数据耗时：69.25秒\n",
      "tb_cis_op_visiting_record_202001_202012.csv\n",
      "读入数据耗时：0.00秒\n",
      "处理数据耗时：78.42秒\n",
      "tb_cis_op_visiting_record_202101_202112.csv\n",
      "读入数据耗时：0.00秒\n",
      "处理数据耗时：96.96秒\n",
      "tb_cis_op_visiting_record_202201_202205.csv\n",
      "读入数据耗时：0.00秒\n",
      "处理数据耗时：57.26秒\n",
      "总数据耗时：836.81秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User2\\AppData\\Local\\Temp/ipykernel_20236/1935839397.py:67: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  result_df.to_excel(r'D:/Output/chenbingying/B1统计/B1关键字段数据质量统计v01.xls',index = False)\n"
     ]
    }
   ],
   "source": [
    "# #读取B2表\n",
    "path1 = r'D:\\Output\\zhuhao\\B1'\n",
    "# file_name_list = ['tb_cis_op_visiting_record_202001_202012.csv']\n",
    "                 \n",
    "file_name_list = ['tb_cis_op_visiting_record_201401_201806.csv',\n",
    "                  'tb_cis_op_visiting_record_201807_201912.csv',\\\n",
    "                  'tb_cis_op_visiting_record_202001_202012.csv',\\\n",
    "                  'tb_cis_op_visiting_record_202101_202112.csv',\\\n",
    "                  'tb_cis_op_visiting_record_202201_202205.csv']\n",
    "\n",
    "result=[]\n",
    "t_start=time()\n",
    "for file_name in file_name_list:\n",
    "    print(file_name)\n",
    "    B2_df = spark.read.option(\"inferSchema\",\"true\").option(\"delimiter\", \",\").option(\"header\",\"true\").csv(os.path.join(path1, file_name))\n",
    "    B2_df.createOrReplaceTempView(\"B2_00\")\n",
    "    start=time()\n",
    "    \n",
    "    print('读入数据耗时：%.2f秒'%(time()-start))\n",
    "    df = spark.sql(\"\"\"\n",
    "    select\n",
    "    count(*)as TOTAL_NUM\n",
    "    ,count(VISITING_DATE)as VISITING_DATE_NOTNULL\n",
    "    ,count(ID_NUMBER)as ID_NUMBER_NOTNULL\n",
    "    ,count(AGE)as AGE_NOTNULL\n",
    "    ,count(GENDER)as GENDER_NOTNULL\n",
    "    ,count(DISEASE_DIAGNOSIS_CODE)as DISEASE_DIAGNOSIS_CODE_NOTNULL\n",
    "    ,count(NAME_OF_DISEASE_DIAGNOSIS)as NAME_OF_DISEASE_DIAGNOSIS_NOTNULL\n",
    "    ,count(DIAGNOSIS_DESCRIPTION)as DIAGNOSIS_DESCRIPTION_NOTNULL\n",
    "    ,count(VISITING_TYPE_CODE)as VISITING_TYPE_CODE_NOTNULL\n",
    "    ,count(VISITING_TYPE_NAME)as VISITING_TYPE_NAME_NOTNULL\n",
    "    ,count(ICD_CODE)as ICD_CODE_NOTNULL\n",
    "    ,count(area)as AREA_NOTNULL\n",
    "    ,sum(case when MEDICAL_INSTITUTION_CODE is not null and FILE_NUMBER is not null then 1 else 0 end) as flag1\n",
    "    ,sum(case when CARD_NUMBER is not null and CARD_TYPE is not null then 1 else 0 end) as flag2\n",
    "    ,sum(case when GENDER is null and id_gender is null then 0 else 1 end) as flag3\n",
    "    ,sum(case when VISITING_DATE is null and DATE_OF_DIAGNOSIS is null then 0 else 1 end) as flag4\n",
    "    ,sum(case when BIRTH_DATE is null and id_birth_date is null then 0 else 1 end) as flag5\n",
    "    ,sum(case when DISEASE_DIAGNOSIS_CODE is null and NAME_OF_DISEASE_DIAGNOSIS is null then 0 else 1 end) as flag6\n",
    "    ,sum(case when ICD_CODE is not null and area is not null then 1 else 0 end) as flag7\n",
    "    from B2_00\"\"\").toPandas()\n",
    "\n",
    "    for col in df.columns:\n",
    "        if (col != 'TOTAL_NUM'):\n",
    "            df.insert(df.columns.get_loc(col)+1,col+'_RATE' ,df[col]/df['TOTAL_NUM']*100)\n",
    "            \n",
    "    result.append(df)\n",
    "\n",
    "    print('处理数据耗时：%.2f秒'%(time()-start))\n",
    "result_df =pd.concat(result)\n",
    "result_df.insert(0,'File',file_name_list)\n",
    "result_df.columns=['文件名','数据总量','VISITING_DATE非空数据量','VISITING_DATE完整率','ID_NUMBER非空数据量','ID_NUMBER完整率',\\\n",
    "                   'AGE非空数据量','AGE完整率','GENDER非空数据量','GENDER完整率',\\\n",
    "                   'DISEASE_DIAGNOSIS_CODE非空数据量','DISEASE_DIAGNOSIS_CODE完整率','NAME_OF_DISEASE_DIAGNOSIS非空数据量',\\\n",
    "                   'NAME_OF_DISEASE_DIAGNOSIS完整率','DIAGNOSIS_DESCRIPTION非空数据量','DIAGNOSIS_DESCRIPTION完整率',\\\n",
    "                   'VISITING_TYPE_CODE非空数据量','VISITING_TYPE_CODE完整率','VISITING_TYPE_NAME非空数据量',\\\n",
    "                   'VISITING_TYPE_NAME完整率','ICD_CODE非空数据量','ICD_CODE完整率',\\\n",
    "                   'AREA非空数据量','AREA完整率',\\\n",
    "                   'MEDICAL_INSTITUTION_CODE,FILE_NUMBER字段组合均非空数据量','MEDICAL_INSTITUTION_CODE,FILE_NUMBER字段组合完整率',\\\n",
    "                   'CARD_TYPE,CARD_NUMBER字段组合均非空数据量','CARD_TYPE,CARD_NUMBER字段组合完整率',\\\n",
    "                   'GENDER,id_gender至少一个非空数据量','GENDER,id_gender至少一个非空完整率',\\\n",
    "                   'VISITING_DATE,DATE_OF_DIAGNOSIS至少一个非空数据量','VISITING_DATE,DATE_OF_DIAGNOSIS至少一个非空完整率',\\\n",
    "                   'BIRTH_DATE,id_birth_date至少一个非空数据量','BIRTH_DATE,id_birth_date至少一个非空完整率',\\\n",
    "                   'DISEASE_DIAGNOSIS_CODE,NAME_OF_DISEASE_DIAGNOSIS至少一个非空数据量',\\\n",
    "                   'DISEASE_DIAGNOSIS_CODE,NAME_OF_DISEASE_DIAGNOSIS至少一个非空完整率',\\\n",
    "                 'ICD_CODE,CITY均非空数据量','ICD_CODE,CITY字段组合完整率']\n",
    "result_df.to_excel(r'D:/Output/chenbingying/B1统计/B1关键字段数据质量统计v01.xls',index = False)\n",
    "print('总数据耗时：%.2f秒'%(time()-t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbfe070",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5007f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
